{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66f4b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14137,
     "status": "ok",
     "timestamp": 1682839562487,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "a66f4b7b",
    "outputId": "5c11b7b0-b5a9-42a5-ceca-d8ca00971e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.3.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.3.0\u001b[0m\u001b[31m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.10/dist-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-rl2) (2.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.20.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.4.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (67.7.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.32.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.12.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (16.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.54.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->keras-rl2) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->keras-rl2) (1.10.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.17.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0\n",
    "!pip install gym\n",
    "!pip install keras\n",
    "!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1HMwq-smm9Qp",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682839562488,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "1HMwq-smm9Qp"
   },
   "outputs": [],
   "source": [
    "#SIMULATOR BY 안의근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e578f513",
   "metadata": {
    "executionInfo": {
     "elapsed": 402,
     "status": "ok",
     "timestamp": 1682839562886,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "e578f513"
   },
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uVmQKjO-SPNd",
   "metadata": {
    "id": "uVmQKjO-SPNd"
   },
   "source": [
    "편의점 방문 빈도 수에 따른 문 여닫는 이벤트를 푸아송 분포로 나타낸 식\n",
    "O(t) = Poisson(λ(t))\n",
    "이제 주어진 시간대별 평균 문 여닫는 이벤트의 수를 나타내는 λ(t)를 사용하여 파이썬 코드로 구현해 보았음.\n",
    "시간대별로 냉장고 문 여닫는 이벤트 발생 횟수의 평균인 λ(t)를 설정\n",
    "이 값들은 임의로 설정된 것이며 실제 사용 상황에 맞추어 조정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lE5PKVvYW3Kc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682839563160,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "lE5PKVvYW3Kc",
    "outputId": "844c0301-4966-414b-c3c4-4ca8bff623d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Example of time-varying lambda (average number of door openings per hour)\n",
    "lambda_t = np.array([1, 0.5, 0.2, 0.1, 0.1, 0.2, 1, 2, 3, 2, 1.5, 1, 1, 1, 1.5, 2, 3, 4, 5, 4, 3, 2, 1, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VEkvFfjXSu7G",
   "metadata": {
    "id": "VEkvFfjXSu7G"
   },
   "source": [
    "이 함수는 시간대별 냉장고 문 여닫는 이벤트를 푸아송 분포를 사용하여 계산. 함수는 람다 값들의 리스트인 lambda_t와 냉장고의 길이(초)인 refri_length를 인수로 받음.\n",
    " 함수는 시간대별로 푸아송 분포에서 샘플링된 이벤트의 수를 저장하는 리스트를 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ip0ZShW9N8",
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1682839652351,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "51ip0ZShW9N8"
   },
   "outputs": [],
   "source": [
    "# def door_opening_event_hourly(lambda_t, t_max):\n",
    "#     event_count = np.random.poisson(lambda_t, (t_max // 3600) + 1)\n",
    "#     hourly_event_count = np.repeat(event_count, 3600)[:t_max]\n",
    "#     return hourly_event_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc384f4",
   "metadata": {
    "id": "cfc384f4"
   },
   "source": [
    "처음의 CustomActionSpace 클래스는 custom action class이다. 현재는 기존의 방식인 Discrete를 이용하여 구현했지만 이것이 의도한대로 작동하지 않을 경우를 위해 미리 작성해 둔 class이다.\n",
    "이는 내가 원하는 임의의 정수들을 action으로 지정하여 그것을 sampling하여 반환하도록 할 수 있고 이 action class 또한 step() 함수의 action 인자로 사용할 수 있다. contain함수는 주어진 action이 Custom action space에 속하는지 여부를 반환하는 함수이다.\n",
    "\n",
    "현재 구현되어 있는 action_space는 mapping을 이용하여 구현해 두었다. 알아본 결과 Discrete는 연속하는 정수만을 담을 수 있고, 내가 원하는 임의의 불연속적인 정수를 담는 것이 불가능하다. 그래서 일단 Discrete를 이용하여 4개의 action_space를 구현하고 그 action space에 내가 원하는 정수(우리는 온도를 의미)를 mapping하여 action_space를 내가 원하는 value로 변환하도록 구현되었다. 이 방법을 사용하려면 action 대신 action_to_value로 바꾸어 호출하면 된다.\n",
    "-> 나중에 모든 코드가 구현되고 나서 확인이 필요할 듯 하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3537be27",
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1682839654413,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "3537be27"
   },
   "outputs": [],
   "source": [
    "class CustomActionSpace(gym.Space):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(4)\n",
    "        self.action_values = [-5, 0, 5, 10]\n",
    "\n",
    "    def sample(self):\n",
    "        return self.action_values[self.action_space.sample()]\n",
    "    \n",
    "    def contains(self, x):\n",
    "        return x in self.action_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9jZ9UE7iY57W",
   "metadata": {
    "id": "9jZ9UE7iY57W"
   },
   "source": [
    "RefriEnv 클래스의 reset 메소드를 수정함. 여기서 door_opening_event_hourly 함수를 호출하여 시간대별 문 여닫는 이벤트 수를 계산하고, 이를 self.hourly_event_count 속성에 저장. 이 속성은 환경이 초기화될 때마다 업데이트됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3c6cde",
   "metadata": {
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1682839881412,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "5b3c6cde"
   },
   "outputs": [],
   "source": [
    "class RefriEnv(Env):\n",
    "    def __init__(self):\n",
    "        #action space\n",
    "        custom_action_space = Discrete(4)\n",
    "        self.action_space = custom_action_space\n",
    "        # The real values are that mapping the action value\n",
    "        # 0 to 3 is mapping the -5,0,5,10\n",
    "        self.action_to_value = {0: -5, 1: 0, 2: 5, 3: 10}\n",
    "        # Temperature array\n",
    "        self.observation_space = Box(low=np.array([-50]), high=np.array([50]))\n",
    "        # Set start temp\n",
    "        self.state = 0 + random.randint(-3,3)\n",
    "        # Set refrigerator length\n",
    "        self.refri_length = 60\n",
    "\n",
    "         # O(t)에 관한 코드\n",
    "        # self.hourly_event_count = door_opening_event_hourly(lambda_t, self.refri_length)\n",
    "\n",
    "    #transform the action to value\n",
    "    def map_action_to_value(self, action):\n",
    "        return self.action_to_value[action]\n",
    "        \n",
    "    #transform the value to action\n",
    "    def map_value_to_action(self, value):\n",
    "        for action, val in self.action_to_value.items():\n",
    "            if val == value:\n",
    "                return action\n",
    "        raise ValueError(\"Invalid value: {}\".format(value))\n",
    "\n",
    "    #RefriEnv 클래스의 step 메소드를 수정했음. \n",
    "    #이 메소드에서 시간대별 문 여닫는 이벤트 수를 고려하여 냉장고의 온도가 업데이트되는 방식을 변경함. \n",
    "    #먼저, 현재 시간대에서 발생하는 이벤트 수를 계산하고, 이 값을 O(t)로 사용\n",
    "    def step(self, action):\n",
    "        # 냉장고의 현재 시간대 계산 //(O(t)에 관한 코드)\n",
    "        #self.refri_length는 냉장고의 에피소드 길이가 몇 초 남았는지를 나타내는 변수\n",
    "        #에피소드가 진행될수록 self.refri_length 값이 감소하며, 0이 되면 에피소드가 종료\n",
    "        current_hour = (self.refri_length - 1) // 3600\n",
    "\n",
    "        # 현재 시간대에 대한 문 여닫는 이벤트 수//(O(t)에 관한 코드)\n",
    "        #self.hourly_event_count는 시간대별 문 여닫는 이벤트 수를 저장하는 리스트\n",
    "        #current_hour 인덱스를 사용하여 현재 시간대에 해당하는 문 여닫는 이벤트 수를 가져옵니다. 이 값을 변수 O에 저장\n",
    "        # O = self.hourly_event_count[current_hour]\n",
    "\n",
    "        P_max=5\n",
    "        T_set=0\n",
    "        y=self.state\n",
    "        delta=3\n",
    "\n",
    "        #P_max 최대 냉각 성능, delta 최대 냉각시 온도와 냉각하지 않는 온도차,\n",
    "        P_cool = P_max / (1 + np.exp(-(y - T_set)/delta))\n",
    "\n",
    "        E=0.5\n",
    "        U=0.2\n",
    "        A=4\n",
    "        T_ext= 20\n",
    "        h=0.2\n",
    "        m=50\n",
    "        c=3\n",
    "        U_o=2\n",
    "\n",
    "        # Apply action\n",
    "        #평소의 상황\n",
    "        if(self.state>action):\n",
    "            self.state += (-P_cool*E-U*A*(self.state-T_ext)+U_o*A*(T_ext-self.state))/(m*c)\n",
    "        else:\n",
    "            self.state += (-U*A*(self.state-T_ext)+U_o*A*(T_ext-self.state))/(m*c)\n",
    "        \n",
    "        # Reduce refrigerator length by 1 second\n",
    "        self.refri_length -= 1 \n",
    "        \n",
    "\n",
    "\n",
    "        P_power = P_cool/E\n",
    "        \n",
    "\n",
    "        # Calculate reward\n",
    "        if self.state>action: \n",
    "            reward = -10\n",
    "            \n",
    "              \n",
    "        else: \n",
    "            reward= -(self.state-action)\n",
    "            \n",
    "        reward -= P_power\n",
    "          # Check if episode is done\n",
    "        if self.refri_length <= 0: \n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Apply temperature noise\n",
    "        #self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset refrigerator temperature\n",
    "        self.state = 0 + random.randint(-3,3)\n",
    "        # Reset refrigerator time\n",
    "        self.refri_length = 60 \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54e996c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1682839884683,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "54e996c2",
    "outputId": "43e370d8-269c-4db2-8da7-36db0288c00e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "env = RefriEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cd02b88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1682839886737,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "2cd02b88",
    "outputId": "b2d76b84-cfca-415c-aa86-41c6f7a4118a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.240381], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a7cecae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1682839888301,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "6a7cecae",
    "outputId": "521f134d-70df-419c-fc8b-f35b146cc151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-1168.0096829482789\n",
      "Episode:2 Score:-1113.9412676592435\n",
      "Episode:3 Score:-1185.8961020731695\n",
      "Episode:4 Score:-1120.9970160363666\n",
      "Episode:5 Score:-1182.6855413361345\n",
      "Episode:6 Score:-1129.1387088396418\n",
      "Episode:7 Score:-1178.8614523712768\n",
      "Episode:8 Score:-1185.92607473862\n",
      "Episode:9 Score:-1174.574212578818\n",
      "Episode:10 Score:-1178.8950162816125\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "zsqvYpHJEwAZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1682839982836,
     "user": {
      "displayName": "김강현",
      "userId": "04365970014820709200"
     },
     "user_tz": -540
    },
    "id": "zsqvYpHJEwAZ",
    "outputId": "8d9b2523-9580-4c98-eff9-d7c5b1c67a5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-51f87e0682b6>:43: UserWarning: frames=None which we can infer the length of, did not pass an explicit *save_count* and passed cache_frame_data=True.  To avoid a possibly unbounded cache, frame data caching has been disabled. To suppress this warning either pass `cache_frame_data=False` or `save_count=MAX_FRAMES`.\n",
      "  ani = FuncAnimation(plt.gcf(), animate, interval = 100)\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/animation.py:884: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-19.983041558398085\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from itertools import count\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    fig, ax = plt.subplots() \n",
    "    x_val = []\n",
    "    y_val1 = []\n",
    "    y_val2 = []\n",
    "    a=0\n",
    "    action1=[]\n",
    "    n_state1=[]\n",
    "\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        action1.append(action)\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        n_state1.append(n_state)\n",
    "        a=a+1\n",
    "        \n",
    "        \n",
    "    index=count()\n",
    "    def animate(i):\n",
    "            x_val.append(next(index))\n",
    "            y_val1.append(action1[i])\n",
    "            y_val2.append(n_state1[i])\n",
    "            plt.cla()\n",
    "            plt.plot(x_val, y_val1,label='action')\n",
    "            plt.plot(x_val, y_val2,label='state')\n",
    "\n",
    "            plt.legend(loc = 'upper left')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "\n",
    "    ani = FuncAnimation(plt.gcf(), animate, interval = 100)\n",
    "    score+=reward\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "\n",
    "    \n",
    "\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14e6ef",
   "metadata": {
    "id": "ee14e6ef"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c38fdf",
   "metadata": {
    "id": "92c38fdf"
   },
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d880ec1",
   "metadata": {
    "id": "9d880ec1",
    "outputId": "b7de799e-cf8e-4502-c1aa-d359a2a15c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93cce6",
   "metadata": {
    "id": "0d93cce6"
   },
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(24, activation='relu', input_shape=states))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00498f",
   "metadata": {
    "id": "7b00498f"
   },
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc70dbb",
   "metadata": {
    "id": "8dc70dbb",
    "outputId": "eb82bb64-1177-439b-f623-c55b21390b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 24)                48        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 75        \n",
      "=================================================================\n",
      "Total params: 723\n",
      "Trainable params: 723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1095c6",
   "metadata": {
    "id": "6e1095c6"
   },
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455d187",
   "metadata": {
    "id": "c455d187"
   },
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a051d",
   "metadata": {
    "id": "713a051d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c0f2c",
   "metadata": {
    "id": "0f1c0f2c",
    "outputId": "fd0268a3-36e8-4cc5-b684-531d79fb3cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "    1/10000 [..............................] - ETA: 5:32 - reward: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mink\\anaconda3\\envs\\openai\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "C:\\Users\\mink\\anaconda3\\envs\\openai\\lib\\site-packages\\rl\\memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 53s 5ms/step - reward: 0.7920\n",
      "166 episodes - episode_reward: 47.530 [-60.000, 60.000] - loss: 6.300 - mae: 16.624 - mean_q: 24.965\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 53s 5ms/step - reward: 0.8532\n",
      "167 episodes - episode_reward: 51.150 [30.000, 60.000] - loss: 13.590 - mae: 27.390 - mean_q: 41.272\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 55s 5ms/step - reward: 0.8736\n",
      "167 episodes - episode_reward: 52.431 [36.000, 60.000] - loss: 13.684 - mae: 27.458 - mean_q: 41.379\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 57s 6ms/step - reward: 0.8814\n",
      "166 episodes - episode_reward: 52.952 [34.000, 60.000] - loss: 14.128 - mae: 27.794 - mean_q: 41.864\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 59s 6ms/step - reward: 0.8598\n",
      "done, took 276.866 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1128eb0a400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad9c3c",
   "metadata": {
    "id": "bfad9c3c",
    "outputId": "785c1772-7e2f-4cb4-86ac-421fa974cc69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: 60.000, steps: 60\n",
      "Episode 2: reward: 60.000, steps: 60\n",
      "Episode 3: reward: 54.000, steps: 60\n",
      "Episode 4: reward: 54.000, steps: 60\n",
      "Episode 5: reward: 58.000, steps: 60\n",
      "Episode 6: reward: 54.000, steps: 60\n",
      "Episode 7: reward: 60.000, steps: 60\n",
      "Episode 8: reward: 60.000, steps: 60\n",
      "Episode 9: reward: 54.000, steps: 60\n",
      "Episode 10: reward: 60.000, steps: 60\n",
      "Episode 11: reward: 60.000, steps: 60\n",
      "Episode 12: reward: 60.000, steps: 60\n",
      "Episode 13: reward: 56.000, steps: 60\n",
      "Episode 14: reward: 60.000, steps: 60\n",
      "Episode 15: reward: 56.000, steps: 60\n",
      "Episode 16: reward: 60.000, steps: 60\n",
      "Episode 17: reward: 54.000, steps: 60\n",
      "Episode 18: reward: 54.000, steps: 60\n",
      "Episode 19: reward: 58.000, steps: 60\n",
      "Episode 20: reward: 54.000, steps: 60\n",
      "Episode 21: reward: 58.000, steps: 60\n",
      "Episode 22: reward: 60.000, steps: 60\n",
      "Episode 23: reward: 60.000, steps: 60\n",
      "Episode 24: reward: 58.000, steps: 60\n",
      "Episode 25: reward: 60.000, steps: 60\n",
      "Episode 26: reward: 54.000, steps: 60\n",
      "Episode 27: reward: 54.000, steps: 60\n",
      "Episode 28: reward: 60.000, steps: 60\n",
      "Episode 29: reward: 60.000, steps: 60\n",
      "Episode 30: reward: 60.000, steps: 60\n",
      "Episode 31: reward: 60.000, steps: 60\n",
      "Episode 32: reward: 60.000, steps: 60\n",
      "Episode 33: reward: 54.000, steps: 60\n",
      "Episode 34: reward: 56.000, steps: 60\n",
      "Episode 35: reward: 58.000, steps: 60\n",
      "Episode 36: reward: 60.000, steps: 60\n",
      "Episode 37: reward: 60.000, steps: 60\n",
      "Episode 38: reward: 60.000, steps: 60\n",
      "Episode 39: reward: 60.000, steps: 60\n",
      "Episode 40: reward: 56.000, steps: 60\n",
      "Episode 41: reward: 60.000, steps: 60\n",
      "Episode 42: reward: 60.000, steps: 60\n",
      "Episode 43: reward: 60.000, steps: 60\n",
      "Episode 44: reward: 60.000, steps: 60\n",
      "Episode 45: reward: 58.000, steps: 60\n",
      "Episode 46: reward: 54.000, steps: 60\n",
      "Episode 47: reward: 56.000, steps: 60\n",
      "Episode 48: reward: 60.000, steps: 60\n",
      "Episode 49: reward: 54.000, steps: 60\n",
      "Episode 50: reward: 54.000, steps: 60\n",
      "Episode 51: reward: 60.000, steps: 60\n",
      "Episode 52: reward: 58.000, steps: 60\n",
      "Episode 53: reward: 60.000, steps: 60\n",
      "Episode 54: reward: 60.000, steps: 60\n",
      "Episode 55: reward: 60.000, steps: 60\n",
      "Episode 56: reward: 56.000, steps: 60\n",
      "Episode 57: reward: 60.000, steps: 60\n",
      "Episode 58: reward: 60.000, steps: 60\n",
      "Episode 59: reward: 58.000, steps: 60\n",
      "Episode 60: reward: 60.000, steps: 60\n",
      "Episode 61: reward: 54.000, steps: 60\n",
      "Episode 62: reward: 60.000, steps: 60\n",
      "Episode 63: reward: 56.000, steps: 60\n",
      "Episode 64: reward: 60.000, steps: 60\n",
      "Episode 65: reward: 60.000, steps: 60\n",
      "Episode 66: reward: 54.000, steps: 60\n",
      "Episode 67: reward: 56.000, steps: 60\n",
      "Episode 68: reward: 54.000, steps: 60\n",
      "Episode 69: reward: 60.000, steps: 60\n",
      "Episode 70: reward: 60.000, steps: 60\n",
      "Episode 71: reward: 56.000, steps: 60\n",
      "Episode 72: reward: 60.000, steps: 60\n",
      "Episode 73: reward: 58.000, steps: 60\n",
      "Episode 74: reward: 58.000, steps: 60\n",
      "Episode 75: reward: 54.000, steps: 60\n",
      "Episode 76: reward: 56.000, steps: 60\n",
      "Episode 77: reward: 58.000, steps: 60\n",
      "Episode 78: reward: 60.000, steps: 60\n",
      "Episode 79: reward: 54.000, steps: 60\n",
      "Episode 80: reward: 58.000, steps: 60\n",
      "Episode 81: reward: 54.000, steps: 60\n",
      "Episode 82: reward: 56.000, steps: 60\n",
      "Episode 83: reward: 60.000, steps: 60\n",
      "Episode 84: reward: 60.000, steps: 60\n",
      "Episode 85: reward: 60.000, steps: 60\n",
      "Episode 86: reward: 60.000, steps: 60\n",
      "Episode 87: reward: 60.000, steps: 60\n",
      "Episode 88: reward: 60.000, steps: 60\n",
      "Episode 89: reward: 60.000, steps: 60\n",
      "Episode 90: reward: 60.000, steps: 60\n",
      "Episode 91: reward: 54.000, steps: 60\n",
      "Episode 92: reward: 60.000, steps: 60\n",
      "Episode 93: reward: 60.000, steps: 60\n",
      "Episode 94: reward: 60.000, steps: 60\n",
      "Episode 95: reward: 58.000, steps: 60\n",
      "Episode 96: reward: 60.000, steps: 60\n",
      "Episode 97: reward: 54.000, steps: 60\n",
      "Episode 98: reward: 60.000, steps: 60\n",
      "Episode 99: reward: 58.000, steps: 60\n",
      "Episode 100: reward: 56.000, steps: 60\n",
      "57.98\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=100, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f21b3",
   "metadata": {
    "id": "440f21b3",
    "outputId": "9f463bd6-8d4f-4073-fe68-5ddca2112153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 15 episodes ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-f3237f5249b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\rl\\core.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                     \u001b[0mreward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\rl\\callbacks.py\u001b[0m in \u001b[0;36mon_action_end\u001b[1;34m(self, action, logs)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'on_action_end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\rl\\callbacks.py\u001b[0m in \u001b[0;36mon_action_end\u001b[1;34m(self, action, logs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_action_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;34m\"\"\" Render environment at the end of each action \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "_ = dqn.test(env, nb_episodes=15, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43fb7a",
   "metadata": {
    "id": "6c43fb7a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
